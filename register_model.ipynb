{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d964c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run nosy-croc-545 at: http://127.0.0.1:8768/#/experiments/17/runs/b3c6f69729824c92b6109f691034a834\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/17\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "The task could not be inferred from the model. If you are saving a custom local model that is not available in the Hugging Face hub, please provide the `task` argument to the `log_model` or `save_model` function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/__init__.py:490\u001b[0m, in \u001b[0;36mget_task\u001b[0;34m(model, token, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 490\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/mnt/data/test-fe8a4e/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/transformers/__init__.py:1524\u001b[0m, in \u001b[0;36m_get_task_for_model\u001b[0;34m(model_name_or_path, default_task)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1524\u001b[0m     model_task \u001b[38;5;241m=\u001b[39m \u001b[43mget_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_task \u001b[38;5;129;01min\u001b[39;00m get_supported_tasks():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/__init__.py:492\u001b[0m, in \u001b[0;36mget_task\u001b[0;34m(model, token, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 492\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstantiating a pipeline without a task set raised an error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpipeline_tag:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Instantiating a pipeline without a task set raised an error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/mnt/data/test-fe8a4e/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_dir)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run() \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Log the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransformers_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello, how are you?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# TODO Check for metadata conflicts if the registered model already exists.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# For example, the model_id must match the existing tag.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Register the model\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     result \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mregister_model(\n\u001b[1;32m     31\u001b[0m         model_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m         name\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m     33\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m registered from Hugging Face\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/transformers/__init__.py:1022\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(transformers_model, artifact_path, processor, task, torch_dtype, model_card, inference_config, code_paths, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, conda_env, metadata, model_config, example_no_conversion, prompt_template, save_pretrained, prompts, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;129m@experimental\u001b[39m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;129m@docstring_version_compatibility_warning\u001b[39m(integration_name\u001b[38;5;241m=\u001b[39mFLAVOR_NAME)\n\u001b[1;32m    793\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39mFLAVOR_NAME))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    817\u001b[0m ):\n\u001b[1;32m    818\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;124;03m    Log a ``transformers`` object as an MLflow artifact for the current run. Note that\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;124;03m    logging transformers models with custom code (i.e. models that require\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;124;03m        kwargs: Additional arguments for :py:class:`mlflow.models.model.Model`\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Get the current module.\u001b[39;49;00m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransformers_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_card\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_card\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# NB: We don't validate the serving input if the provided model is a path\u001b[39;49;00m\n\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# to a local checkpoint. This is because the purpose of supporting that\u001b[39;49;00m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# input format is to avoid loading large model into memory. Serving input\u001b[39;49;00m\n\u001b[1;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# validation loads the model into memory and make prediction, which is\u001b[39;49;00m\n\u001b[1;32m   1042\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# expensive and can cause OOM errors.\u001b[39;49;00m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_serving_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_no_conversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_no_conversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_pretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/models/model.py:855\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m [pr\u001b[38;5;241m.\u001b[39muri \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pr, Prompt) \u001b[38;5;28;01melse\u001b[39;00m pr \u001b[38;5;28;01mfor\u001b[39;00m pr \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m    847\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    848\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[1;32m    849\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mprompts,\n\u001b[1;32m    854\u001b[0m )\n\u001b[0;32m--> 855\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result in\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path)\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pycache__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/transformers/__init__.py:508\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(transformers_model, path, processor, task, torch_dtype, model_card, inference_config, code_paths, mlflow_model, signature, input_example, pip_requirements, extra_pip_requirements, conda_env, metadata, model_config, example_no_conversion, prompt_template, save_pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transformers_model, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    507\u001b[0m     _validate_transformers_model_dict(transformers_model)\n\u001b[0;32m--> 508\u001b[0m     built_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43m_build_pipeline_from_model_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformers_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transformers_model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# When a string is passed, it should be a path to model checkpoint in local storage or DBFS\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transformers_model\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbfs:\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;66;03m# Replace the DBFS URI to the actual mount point\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/transformers/__init__.py:1500\u001b[0m, in \u001b[0;36m_build_pipeline_from_model_input\u001b[0;34m(model_dict, task)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m task\u001b[38;5;241m.\u001b[39mstartswith(_LLM_INFERENCE_TASK_PREFIX):\n\u001b[1;32m   1499\u001b[0m     default_task \u001b[38;5;241m=\u001b[39m _get_default_task_for_llm_inference_task(task)\n\u001b[0;32m-> 1500\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[43m_get_task_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_task\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress_logs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.pipelines.base\u001b[39m\u001b[38;5;124m\"\u001b[39m, filter_regex\u001b[38;5;241m=\u001b[39m_PEFT_PIPELINE_ERROR_MSG):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/transformers/__init__.py:1546\u001b[0m, in \u001b[0;36m_get_task_for_model\u001b[0;34m(model_name_or_path, default_task)\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default_task:\n\u001b[1;32m   1545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_task\n\u001b[0;32m-> 1546\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m   1547\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe task could not be inferred from the model. If you are saving a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1548\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal model that is not available in the Hugging Face hub, please provide \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe `task` argument to the `log_model` or `save_model` function.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1550\u001b[0m     error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m   1551\u001b[0m ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mMlflowException\u001b[0m: The task could not be inferred from the model. If you are saving a custom local model that is not available in the Hugging Face hub, please provide the `task` argument to the `log_model` or `save_model` function."
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer\n",
    "import mlflow.transformers\n",
    "\n",
    "# Input arguments\n",
    "model_dir = \"/mnt/data/test-fe8a4e/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6\"\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "revision = \"fe8a4ea1ffedaf415f4da2f062534de366a451e6\"\n",
    "model_type = \"LLM\"\n",
    "\n",
    "# Load the model and tokenizer from model_dir based on model_type\n",
    "if model_type == \"LLM\":\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_dir)\n",
    "else:\n",
    "    model = AutoModel.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # Log the model\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model={\"model\": model, \"tokenizer\": tokenizer},\n",
    "        artifact_path=\"model\",\n",
    "        input_example=\"Hello, how are you?\",\n",
    "    )\n",
    "\n",
    "    # TODO Check for metadata conflicts if the registered model already exists.\n",
    "    # For example, the model_id must match the existing tag.\n",
    "\n",
    "    # Register the model\n",
    "    result = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run.info.run_id}/model\",\n",
    "        name=model_id,\n",
    "        description=f\"{model_id} registered from Hugging Face\",\n",
    "    )\n",
    "    print(f\"Registered model={model_id}, version={result.version}\")\n",
    "    \n",
    "client = MlflowClient()\n",
    "\n",
    "# Tag the registered model\n",
    "if result.version == 1:\n",
    "    client.set_registered_model_tag(name=model_id, key=\"mlflow.domino.model_id\", value=model_id)\n",
    "    client.set_registered_model_tag(name=model_id, key=\"mlflow.domino.model_type\", value=model_type)\n",
    "\n",
    "# Tag the registered model version\n",
    "client.set_model_version_tag(\n",
    "    name=model_id,\n",
    "    version=result.version,\n",
    "    key=\"mlflow.domino.model_version\",\n",
    "    value=revision,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb49990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
